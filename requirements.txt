# requirements.txt
selenium==4.15.0
pandas==2.1.3
numpy==1.24.3
scipy==1.11.4
matplotlib==3.8.2
seaborn==0.13.0
scikit-learn==1.3.2
requests==2.31.0
dnspython==2.4.2

# domains.json - Sample domain list for testing
{
  "e-commerce": [
    {"domain": "amazon.com", "region": "US", "alexa_rank": 14},
    {"domain": "ebay.com", "region": "US", "alexa_rank": 45},
    {"domain": "alibaba.com", "region": "CN", "alexa_rank": 67},
    {"domain": "shopify.com", "region": "CA", "alexa_rank": 156},
    {"domain": "jumia.com", "region": "AF", "alexa_rank": 890},
    {"domain": "mercadolibre.com", "region": "LA", "alexa_rank": 234}
  ],
  "news": [
    {"domain": "bbc.com", "region": "EU", "alexa_rank": 98},
    {"domain": "cnn.com", "region": "US", "alexa_rank": 78},
    {"domain": "aljazeera.com", "region": "ME", "alexa_rank": 456},
    {"domain": "lemonde.fr", "region": "EU", "alexa_rank": 234},
    {"domain": "xinhuanet.com", "region": "CN", "alexa_rank": 189},
    {"domain": "hespress.com", "region": "AF", "alexa_rank": 1234}
  ],
  "social": [
    {"domain": "facebook.com", "region": "US", "alexa_rank": 3},
    {"domain": "twitter.com", "region": "US", "alexa_rank": 8},
    {"domain": "linkedin.com", "region": "US", "alexa_rank": 23},
    {"domain": "instagram.com", "region": "US", "alexa_rank": 6},
    {"domain": "weibo.com", "region": "CN", "alexa_rank": 56},
    {"domain": "vk.com", "region": "EU", "alexa_rank": 67}
  ],
  "government": [
    {"domain": "gov.uk", "region": "EU", "alexa_rank": 567},
    {"domain": "usa.gov", "region": "US", "alexa_rank": 678},
    {"domain": "gov.ma", "region": "AF", "alexa_rank": 2345},
    {"domain": "canada.ca", "region": "CA", "alexa_rank": 890},
    {"domain": "gov.au", "region": "AU", "alexa_rank": 1234}
  ],
  "education": [
    {"domain": "mit.edu", "region": "US", "alexa_rank": 234},
    {"domain": "harvard.edu", "region": "US", "alexa_rank": 345},
    {"domain": "ox.ac.uk", "region": "EU", "alexa_rank": 456},
    {"domain": "ump.ac.ma", "region": "AF", "alexa_rank": 12345},
    {"domain": "sorbonne-universite.fr", "region": "EU", "alexa_rank": 2345}
  ]
}

# docker-compose.yml
version: '3.8'

services:
  tracking-analyzer:
    build: .
    volumes:
      - ./results:/app/results
      - ./plots:/app/plots
      - ./logs:/app/logs
    environment:
      - DISPLAY=:99
    depends_on:
      - selenium-hub
      - chrome
      - firefox

  selenium-hub:
    image: selenium/hub:4.15.0
    container_name: selenium-hub
    ports:
      - "4442:4442"
      - "4443:4443"
      - "4444:4444"

  chrome:
    image: selenium/node-chrome:4.15.0
    shm_size: 2gb
    depends_on:
      - selenium-hub
    environment:
      - HUB_HOST=selenium-hub
      - HUB_PORT=4444
    volumes:
      - ./extensions:/opt/selenium/extensions

  firefox:
    image: selenium/node-firefox:4.15.0
    shm_size: 2gb
    depends_on:
      - selenium-hub
    environment:
      - HUB_HOST=selenium-hub
      - HUB_PORT=4444

# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    unzip \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Chrome
RUN wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# Install Firefox
RUN apt-get update && apt-get install -y firefox-esr && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create directories
RUN mkdir -p results plots logs extensions

# Run the application
CMD ["python", "web_tracking_analyzer.py"]

# Makefile
.PHONY: setup install run clean test docker-build docker-run

# Setup virtual environment and install dependencies
setup:
	python -m venv venv
	. venv/bin/activate && pip install -r requirements.txt

# Install dependencies
install:
	pip install -r requirements.txt

# Run the analysis
run:
	python web_tracking_analyzer.py

# Clean up generated files
clean:
	rm -rf results/
	rm -rf plots/
	rm -f *.db
	rm -f *.log
	rm -f analysis_report.json

# Run tests
test:
	python -m pytest tests/ -v

# Build Docker image
docker-build:
	docker-compose build

# Run with Docker
docker-run:
	docker-compose up

# Stop Docker containers
docker-stop:
	docker-compose down

# Setup extensions directory and download extensions
setup-extensions:
	mkdir -p extensions
	@echo "Please manually download browser extensions:"
	@echo "1. uBlock Origin: https://github.com/gorhill/uBlock/releases"
	@echo "2. Privacy Badger: https://github.com/EFForg/privacybadger/releases"
	@echo "Place .crx files in the extensions/ directory"

# Generate sample analysis report
sample-report:
	python -c "from web_tracking_analyzer import *; analyzer = StatisticalAnalyzer(DatabaseManager()); print('Sample analysis framework ready')"